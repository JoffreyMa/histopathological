{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed7e223-fd27-4de1-837a-58d6b648f8ca",
   "metadata": {},
   "source": [
    "# Emancipate from Hugging Face and its limits\n",
    "\n",
    "\n",
    "This implementation of Swin is in the transformers package by huggingface.\\\n",
    "Originally it is developped by Microsoft.\\\n",
    "\n",
    "In the transformers library, the model is declared here \n",
    "https://github.com/huggingface/transformers/blob/v4.26.1/src/transformers/models/swin/modeling_swin.py#L1152\n",
    "and is a child of SwinPreTrainedModel.\\\n",
    "At the end of initialization it calls PreTrainedModel.post_init method (SwinPreTrainedModel inherits from PreTrainedModel).\\\n",
    "The method itself calls self.init_weights() and itself the self._init_weights() from the child class\n",
    "\n",
    "\n",
    "What's more I can do data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91fbc85-f0d2-4b8a-ab58-92c447880982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from transformers import SwinConfig, SwinForImageClassification, ViTImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, WeightedRandomSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import gc\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification, DefaultDataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a47212-b4e5-4f30-b724-a57e064eaa76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # in case gpu does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1211e5cb-67c3-4e3f-bb6e-84dfa4e7ceef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" # in case gpu does not work and the above does not work either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea1339-6224-47bb-a642-2b4635f16d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Config\n",
    "\n",
    "Import config of swin alread trained on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d1de26-e323-4835-b992-721526070a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shadow\\\\Documents\\\\Projets\\\\MastereIA\\\\DataChallenge\\\\histopathological\\\\exploration\\\\..'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home = os.path.join(os.getcwd(), \"..\")\n",
    "home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1c0f0b-1259-48ae-b61e-6990b93c896c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_json = os.path.join(home, \"data\", \"model\", \"config\", \"config.json\")\n",
    "preprocessor_config_json = os.path.join(home, \"data\", \"model\", \"config\", \"preprocessor_config.json\")\n",
    "input_train = os.path.join(home, \"data\", \"input\", \"Train\")\n",
    "model_path = os.path.join(home, \"data\", \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d40b1d-46af-40a5-8688-6a1dd5f9aacd",
   "metadata": {},
   "source": [
    "I get a pre-trained model from Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e938d454-b898-49a0-b09d-f5ef3ed6616d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# possibilities from most likely to less\n",
    "# microsoft/swin-base-patch4-window7-224\n",
    "# microsoft/swin-base-patch4-window7-224-in22k\n",
    "pretrained_model = SwinForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a62f9a-4a77-4fe9-a6a7-92764edba4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pretrained_model.swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b839f989-adf9-4c65-a8f8-8c38b774f815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(config_json, 'r') as f:\n",
    "  swin_config_args = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc1b428-90ec-4144-aa10-10e83a5bbc94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configuration = SwinConfig(**swin_config_args)\n",
    "#configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e31a6f-54af-400f-9db5-5f555ec6fba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SwinForImageClassification(configuration)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4ea886-c37d-4418-8322-178ae8a5d2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.swin = pretrained_model.swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "477d54da-3681-4420-8c50-e4fdb7144bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=8, bias=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61a21e8-ea5a-4ff5-a99c-8bd5f2d248cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(preprocessor_config_json, 'r') as f:\n",
    "  vit_prepro_config_args = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0736cc-081e-46aa-adf4-81359e6d8de4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = ViTImageProcessor(**vit_prepro_config_args)\n",
    "extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782902f3-ce91-49f2-8260-da9da6e181cb",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781666dc-2a9d-4349-afcb-6facc830044d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_fn(filename):\n",
    "    # <BIOPSY_PROCEDURE>_<TUMOR_CLASS>_<TUMOR_TYPE>-<YEAR>-<SLIDE_ID>-<MAG>-<SEQ>\n",
    "    parsed = filename[:-4].replace('-', '_').split('_')\n",
    "    parsed.append(filename)\n",
    "    return parsed\n",
    "\n",
    "def parse_type_id(filename):\n",
    "    parsed = parse_fn(filename)\n",
    "    label_maps = {'F':'1', 'DC':'2', 'PC':'3', 'PT':'4', 'MC':'5', 'LC':'6', 'A':'7', 'TA':'8'}\n",
    "    return int(label_maps[parsed[2]])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee10cc64-6892-4415-b740-e39c64bd46aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HistoDataset(Dataset):\n",
    "    def __init__(self, img_dir, train=False, predict=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.train = train\n",
    "        self.predict = predict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(path=self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = os.listdir(path=self.img_dir)[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = read_image(img_path)\n",
    "        if self.train:\n",
    "            composed = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.ColorJitter(brightness=.1, contrast=0, saturation=.1, hue=.1), \n",
    "                                transforms.RandomHorizontalFlip(0.3), \n",
    "                                transforms.RandomVerticalFlip(0.3),\n",
    "                                transforms.RandomRotation(30),\n",
    "                                transforms.TrivialAugmentWide(),\n",
    "                                transforms.RandomApply(transforms=[transforms.RandomResizedCrop(size=(460, 700))], p=0.5),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std), \n",
    "                                transforms.RandomErasing(0.5),\n",
    "                                ])\n",
    "            image = composed(image)\n",
    "        if self.predict:\n",
    "            label='Unknown'\n",
    "        else:\n",
    "            label = parse_type_id(filename)\n",
    "        image_features = extractor(image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "        return {'pixel_values':image_features, 'label':label, 'filename':filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70009506-6c31-4b74-b6cf-86c6de91249f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histoDataset_train = HistoDataset(input_train, train=True)\n",
    "#train_dataset, _, _ = random_split(histoDataset_train, [0.70, 0.20, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "train_dataset, _ = random_split(histoDataset_train, [0.78, 0.22], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465bead8-5881-4eb9-8987-e5da103df1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histoDataset_eval_chal = HistoDataset(input_train, train=False)\n",
    "#_, eval_dataset, challenge_dataset = random_split(histoDataset_eval_chal, [0.70, 0.20, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "_, eval_dataset = random_split(histoDataset_eval_chal, [0.78, 0.22], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1a7697-0046-40c4-ac08-cc07557a39a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_dataset[0]['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc2b555c-2c14-4350-9110-dc62a07c29ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_dataset[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28fe117c-2450-4df9-ace6-3482ccbddc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.imshow(train_dataset[0]['pixel_values'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26aed957-58d5-4ddd-91a1-433cdb9b155a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.imshow(eval_dataset[0]['pixel_values'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc751406-9425-4b9f-9dec-4b3000d42707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 92)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset)#, len(challenge_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965e986-1fdf-4692-a119-0feaf1d3ad82",
   "metadata": {},
   "source": [
    "---\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f951e05-7a6b-48e0-8641-0a9085eb5198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checkpoint_path = torch.load(os.path.join(home, \"data\", 'output/swin/checkpoint-1300-reproduce-layer1_2_3_4_retrain/pytorch_model.bin'))\n",
    "#model.load_state_dict(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b001489-4376-4d88-bbab-8531df2ef1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To unfreeze some selected layers\n",
    "#len(pretrained_model.swin.encoder.layers) ==> 4 layers\n",
    "for i in range(0, 4):\n",
    "    for param in model.swin.encoder.layers[i].parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d324cd5f-3c3c-4fb8-a8b4-763506837bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# To check if the earlier layers are frozen\n",
    "for param in model.swin.encoder.layers[1].parameters():\n",
    "    print(param.requires_grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5bce524-4193-4258-b344-7e615290eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoTrainer(Trainer):\n",
    "    def compute_label_counts(self):\n",
    "        \"\"\"Compute the number of samples per class in the training dataset.\"\"\"\n",
    "        label_counts = {}\n",
    "        for elt in self.train_dataset:\n",
    "            label = elt['label']\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "        label_counts = dict(sorted(label_counts.items(), key=lambda x: x[0]))\n",
    "        return label_counts\n",
    "    \n",
    "    def get_train_dataloader(self):\n",
    "        train_dataset = self.train_dataset\n",
    "        data_collator = self.data_collator\n",
    "        if isinstance(train_dataset, Dataset):\n",
    "            train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "        else:\n",
    "            data_collator = self._get_collator_with_removed_columns(data_collator, description=\"training\")\n",
    "            \n",
    "        '''\n",
    "        label_counts = self.compute_label_counts()\n",
    "        max_samples = max(label_counts.values())\n",
    "        classes_weights = {k: max_samples/v for k, v in label_counts.items()}\n",
    "        #print(classes_weights)\n",
    "        sample_weights = torch.DoubleTensor([classes_weights[elt['label']] for elt in train_dataset]).cuda()\n",
    "        '''\n",
    "        sample_weights = torch.DoubleTensor([1 for elt in train_dataset]).cuda()\n",
    "        \n",
    "        # Calculate class weights based on the frequency of each class in the training dataset\n",
    "        #sample_weights = torch.tensor(list(classes_weights.values()), dtype=torch.float).cuda()\n",
    "        # Create a weighted sampler that oversamples the minority class during training\n",
    "        train_sampler = WeightedRandomSampler(sample_weights, len(self.train_dataset))\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self._train_batch_size,\n",
    "            sampler=train_sampler,\n",
    "            collate_fn=data_collator,\n",
    "            drop_last=self.args.dataloader_drop_last,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "            pin_memory=self.args.dataloader_pin_memory,\n",
    "        )\n",
    "        return train_dataloader\n",
    "    \n",
    "    # If weights for classes are needed\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # compute custom loss\n",
    "        loss_fct = CrossEntropyLoss(weight=torch.tensor([0.2, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1]).cuda())\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce0f5077-9f6d-444f-83c8-6c4d3c1d0e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../data/output/swin',          # output directory\n",
    "    num_train_epochs=128,              # total # of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    #warmup_ratio=0.01,\n",
    "    warmup_steps=50,                # number of warmup steps for learning rate scheduler\n",
    "    logging_dir='../data/log',            # directory for storing logs\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    remove_unused_columns = False,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=5e-5,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #ignore_data_skip=True,\n",
    "    #resume_from_checkpoint=True,\n",
    "    #no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = Trainer( #HistoTrainer\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=eval_dataset,            # evaluation dataset\n",
    "    #data_collator=DefaultDataCollator(return_tensors=\"pt\"),\n",
    "    #tokenizer=extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ded0b56-5473-41c4-9e18-e4078e7b9b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainer.compute_label_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d77fe-b8d8-437d-906e-29b7b543c43d",
   "metadata": {},
   "source": [
    "in our prediction file (computed with hugging face which has good results) :\\\n",
    "0    17\\\n",
    "1    54\\\n",
    "2    29\\\n",
    "3    25\\\n",
    "4    25\\\n",
    "6    56\\\n",
    "7     1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d46e9f0c-8cba-4421-971d-8c1ab1adecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to avoid errors such as  :\n",
    "# OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 8.00 GiB total capacity; 6.97 GiB already allocated; 0 bytes free; 7.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db239bc5-31aa-45b9-9abf-7f9381dc6f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checkpoint_path = os.path.join(home, \"data\", 'output/swin/checkpoint-1300')\n",
    "#trainer.train(checkpoint_path)\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75b96f-0dd6-4d55-b47b-ccada029e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cdc77-afaf-4805-aa02-6cb4151e5fd8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluating how good the training went.\n",
    "\n",
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61a97d2f-b054-4f11-93ae-2e2feed04c94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinForImageClassification(\n",
       "  (swin): SwinModel(\n",
       "    (embeddings): SwinEmbeddings(\n",
       "      (patch_embeddings): SwinPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): SwinEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (12): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (13): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (14): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (15): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (16): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (17): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinLayer(\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in case of overfitting to check another checkpoint\n",
    "checkpoint_path = torch.load(os.path.join(home, \"data\", 'output/swin/checkpoint-5300/pytorch_model.bin'))\n",
    "model.load_state_dict(checkpoint_path)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "795aebb9-5ebf-45c1-93f4-19d6cc356689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in train_dataset:\n",
    "        train_labels.append(data['label'])\n",
    "        x = data['pixel_values'][None, :].to(device) # important if inputs and weights are not on the same processing unit\n",
    "        train_preds.append(model(x).logits.argmax(-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9cdf32b-1f09-43a2-9146-1159b64b06e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40,  1,  1,  7,  9,  2,  2,  0],\n",
       "        [ 1, 18,  6,  0,  2,  4,  4,  0],\n",
       "        [ 4,  3, 35,  5,  7,  7,  5,  0],\n",
       "        [ 6,  0,  3, 24,  5,  3,  2,  0],\n",
       "        [ 3,  6,  1,  3, 25,  3,  4,  0],\n",
       "        [ 2,  0,  2,  1,  0,  8,  0,  0],\n",
       "        [ 7,  1,  7,  4,  1,  1, 34,  0],\n",
       "        [ 2,  0,  1,  2,  0,  0,  1,  5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor(train_labels)\n",
    "preds = torch.tensor(train_preds)\n",
    "metric = MulticlassConfusionMatrix(num_classes=8)\n",
    "metric(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280052b5-4226-4fb7-baf4-072df17712ef",
   "metadata": {},
   "source": [
    "It went pretty well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f247a82f-1b29-44e0-b0c7-bd719b9b5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_labels = []\n",
    "eval_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in eval_dataset:\n",
    "        eval_labels.append(data['label'])\n",
    "        x = data['pixel_values'][None, :].to(device) # important if inputs and weights are not on the same processing unit\n",
    "        eval_preds.append(model(x).logits.argmax(-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fc9615c-c4a5-4c18-89f7-a2c85d36ce44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 11,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 26,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0, 13,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0, 13,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  3,  0,  0],\n",
       "        [ 0,  0,  0,  1,  0,  0,  9,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = MulticlassConfusionMatrix(num_classes=8)\n",
    "metric(torch.tensor(eval_preds), torch.tensor(eval_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a5433-dd92-4efe-a2d8-04be991afe3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validation metrics bundle\n",
    "\n",
    "Obtain the results on the autotrain page :\n",
    "\n",
    "    Loss: 0.179\n",
    "    Accuracy: 0.966\n",
    "    Macro F1: 0.959\n",
    "    Micro F1: 0.966\n",
    "    Weighted F1: 0.966\n",
    "    Macro Precision: 0.969\n",
    "    Micro Precision: 0.966\n",
    "    Weighted Precision: 0.969\n",
    "    Macro Recall: 0.954\n",
    "    Micro Recall: 0.966\n",
    "    Weighted Recall: 0.966\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f2a24af-4dd6-458e-a1b0-3e1451c0f058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'f1_macro': 1.0,\n",
       " 'f1_micro': 1.0,\n",
       " 'f1_weighted': 1.0,\n",
       " 'precision_macro': 1.0,\n",
       " 'precision_micro': 1.0,\n",
       " 'precision_weighted': 1.0,\n",
       " 'recall_macro': 1.0,\n",
       " 'recall_micro': 1.0,\n",
       " 'recall_weighted': 1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics (labels, preds):\n",
    "    results = {}\n",
    "    results.update(accuracy_metric.compute(predictions=preds, references = labels))\n",
    "    results.update({'f1_macro':f1_metric.compute(predictions=preds, references = labels, average=\"macro\")['f1']})\n",
    "    results.update({'f1_micro':f1_metric.compute(predictions=preds, references = labels, average=\"micro\")['f1']})\n",
    "    results.update({'f1_weighted':f1_metric.compute(predictions=preds, references = labels, average=\"weighted\")['f1']})\n",
    "    results.update({'precision_macro':precision_metric.compute(predictions=preds, references = labels, average=\"macro\")['precision']})\n",
    "    results.update({'precision_micro':precision_metric.compute(predictions=preds, references = labels, average=\"micro\")['precision']})\n",
    "    results.update({'precision_weighted':precision_metric.compute(predictions=preds, references = labels, average=\"weighted\")['precision']})\n",
    "    results.update({'recall_macro':recall_metric.compute(predictions=preds, references = labels, average=\"macro\")['recall']})\n",
    "    results.update({'recall_micro':recall_metric.compute(predictions=preds, references = labels, average=\"micro\")['recall']})\n",
    "    results.update({'recall_weighted':recall_metric.compute(predictions=preds, references = labels, average=\"weighted\")['recall']})\n",
    "    return results\n",
    "\n",
    "compute_metrics(torch.tensor(train_labels), torch.tensor(train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72d49c86-951e-47ab-ad96-0efb6f82d909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9782608695652174,\n",
       " 'f1_macro': 0.9785401002506267,\n",
       " 'f1_micro': 0.9782608695652174,\n",
       " 'f1_weighted': 0.9782336275471287,\n",
       " 'precision_macro': 0.9797077922077922,\n",
       " 'precision_micro': 0.9782608695652174,\n",
       " 'precision_weighted': 0.9792490118577075,\n",
       " 'recall_macro': 0.9785714285714286,\n",
       " 'recall_micro': 0.9782608695652174,\n",
       " 'recall_weighted': 0.9782608695652174}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(torch.tensor(eval_labels), torch.tensor(eval_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c70da-3978-4ea9-b17c-4c0669f7df48",
   "metadata": {},
   "source": [
    "## Prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe78fd2d-7426-4c3c-86ee-5b2f3b32beac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure</th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOB</td>\n",
       "      <td>1</td>\n",
       "      <td>SOB_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOB</td>\n",
       "      <td>10</td>\n",
       "      <td>SOB_10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOB</td>\n",
       "      <td>100</td>\n",
       "      <td>SOB_100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOB</td>\n",
       "      <td>101</td>\n",
       "      <td>SOB_101.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOB</td>\n",
       "      <td>102</td>\n",
       "      <td>SOB_102.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  procedure   id     filename  type_id\n",
       "0       SOB    1    SOB_1.png        0\n",
       "1       SOB   10   SOB_10.png        0\n",
       "2       SOB  100  SOB_100.png        0\n",
       "3       SOB  101  SOB_101.png        0\n",
       "4       SOB  102  SOB_102.png        0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = os.path.join(os.getcwd(), '..')\n",
    "data = os.path.join(wd, 'data', 'input')\n",
    "image_test_path = os.path.join(data, 'Test')\n",
    "\n",
    "# Test images\n",
    "images_test = os.listdir(path=image_test_path)\n",
    "submission_path = os.path.join(wd, 'data', 'output', 'submission', 'pred_swim_20230307_0002.csv')\n",
    "\n",
    "def parseTest_fn(filename):\n",
    "    # <BIOPSY_PROCEDURE>_<ID>\n",
    "    parsed = filename[:-4].split('_')\n",
    "    parsed.append(filename)\n",
    "    return parsed\n",
    "\n",
    "columns = ['procedure', 'id', 'filename']\n",
    "\n",
    "df_test = pd.DataFrame(list(map(parseTest_fn, images_test)), columns=columns)\n",
    "df_test['type_id'] = 0\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66db0037-7585-4291-a2f6-dee1a0a505a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = HistoDataset(image_test_path, predict=True)\n",
    "types_test = []\n",
    "for data in test_data:\n",
    "    #inputs = extractor(data['pixel_values'], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        #logits = model(inputs['pixel_values'].cuda()).logits\n",
    "        # predicted_label = logits.argmax(-1).item()\n",
    "        x = data['pixel_values'][None, :].to(device)\n",
    "        predicted_label = model(x).logits.argmax(-1).item()\n",
    "        types_test.append(model.config.id2label[predicted_label])\n",
    "    \n",
    "    #train_labels.append(data['label'])\n",
    "    #x = data['pixel_values'][None, :].to(device) # important if inputs and weights are not on the same processing unit\n",
    "    #train_preds.append(model(x).logits.argmax(-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "640a6fec-56a4-444b-a92b-1d817729ea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['type_id'] = types_test\n",
    "df_pred = df_test[['id', 'type_id']]\n",
    "df_pred.to_csv(submission_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807df17-b30e-44f4-813a-63501c2ffdb3",
   "metadata": {},
   "source": [
    "## Compare Auto and Microsoft base\n",
    "\n",
    "Where are the differences in weights ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f71c91dc-d5c0-4f72-9090-e2b98500f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_model = SwinForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224\")\n",
    "#pretrained_model = SwinForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3846576b-d01f-4ac0-a704-7f8c594825e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint_path = torch.load(os.path.join(home, \"data\", 'output/swin/checkpoint-200/pytorch_model.bin'))\n",
    "#model.load_state_dict(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fabbaaeb-43b0-45d4-aae3-bfb87f234ee3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Shadow/.cache\\huggingface\\hub\\models--JoffreyMa--autotrain-histopathological_image_classification-3393093038\\snapshots\\ce7023a6fa2db96df4164220b0bca00a61b32548\\config.json\n",
      "Model config SwinConfig {\n",
      "  \"_name_or_path\": \"JoffreyMa/autotrain-histopathological_image_classification-3393093038\",\n",
      "  \"architectures\": [\n",
      "    \"SwinForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    18,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 128,\n",
      "  \"encoder_stride\": 32,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"1\",\n",
      "    \"1\": \"2\",\n",
      "    \"2\": \"3\",\n",
      "    \"3\": \"4\",\n",
      "    \"4\": \"5\",\n",
      "    \"5\": \"6\",\n",
      "    \"6\": \"7\",\n",
      "    \"7\": \"8\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"1\": \"0\",\n",
      "    \"2\": \"1\",\n",
      "    \"3\": \"2\",\n",
      "    \"4\": \"3\",\n",
      "    \"5\": \"4\",\n",
      "    \"6\": \"5\",\n",
      "    \"7\": \"6\",\n",
      "    \"8\": \"7\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_length\": 128,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    4,\n",
      "    8,\n",
      "    16,\n",
      "    32\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"out_features\": null,\n",
      "  \"padding\": \"max_length\",\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 7\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Shadow/.cache\\huggingface\\hub\\models--JoffreyMa--autotrain-histopathological_image_classification-3393093038\\snapshots\\ce7023a6fa2db96df4164220b0bca00a61b32548\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing SwinForImageClassification.\n",
      "\n",
      "All the weights of SwinForImageClassification were initialized from the model checkpoint at JoffreyMa/autotrain-histopathological_image_classification-3393093038.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SwinForImageClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#access_token = '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'\n",
    "#autotrain_model = AutoModelForImageClassification.from_pretrained(\"JoffreyMa/autotrain-histopathological_image_classification-3393093038\", use_auth_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "439ef77d-4a4c-4a31-83d5-02f7482e17b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layer 0 : 0.00018857356917578727\n",
      "For layer 1 : 0.0001739619328873232\n",
      "For layer 2 : 0.00023301976034417748\n",
      "For layer 3 : 0.0006321489927358925\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # Get the model parameters\n",
    "    params1 = model.swin.encoder.layers[i].state_dict()\n",
    "    params2 = autotrain_model.swin.encoder.layers[i].state_dict()\n",
    "\n",
    "    # Compare the weight tensors layer by layer\n",
    "    means = []\n",
    "    for layer_name, _ in params1.items():\n",
    "        diff = torch.abs(params1[layer_name].cpu() - params2[layer_name]).float()\n",
    "        mean_diff = torch.mean(diff)\n",
    "        means.append(mean_diff)\n",
    "        #print(f\"Layer name: {layer_name}\")\n",
    "        #print(f\"Mean absolute difference: {mean_diff:.6f}\")\n",
    "    print(f'For layer {i} : {np.mean(means)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32cd8e9c-bba7-4f1d-8d96-d4580326b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col2\n",
      "1    47\n",
      "2    28\n",
      "3    35\n",
      "4    20\n",
      "5    38\n",
      "6     1\n",
      "7    36\n",
      "8     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into pandas dataframe\n",
    "df = pd.read_csv( os.path.join(home, \"data/output/submission/pred_swim_20230305_0925.csv\"), header=None)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = [\"col1\", \"col2\"]\n",
    "\n",
    "# Count the number of rows for each distinct value in the second column\n",
    "counts = df.groupby(\"col2\").size()\n",
    "\n",
    "# Print the result\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a714f13-d542-4c51-a09d-25a2f85ae243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col2\n",
      "1    17\n",
      "2    54\n",
      "3    29\n",
      "4    25\n",
      "5    25\n",
      "7    56\n",
      "8     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into pandas dataframe\n",
    "df = pd.read_csv( os.path.join(home, \"data/output/submission/pred_swim_20231002.csv\"), header=None)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = [\"col1\", \"col2\"]\n",
    "\n",
    "# Count the number of rows for each distinct value in the second column\n",
    "counts = df.groupby(\"col2\").size()\n",
    "\n",
    "# Print the result\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "438e23fd-58e1-49c1-896c-5ddb4fa56292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col2\n",
      "1    22\n",
      "2    50\n",
      "3    32\n",
      "4    20\n",
      "5    17\n",
      "7    65\n",
      "8     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into pandas dataframe\n",
    "df = pd.read_csv( os.path.join(home, \"data/output/submission/pred_swim_20230307_0002.csv\"), header=None)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = [\"col1\", \"col2\"]\n",
    "\n",
    "# Count the number of rows for each distinct value in the second column\n",
    "counts = df.groupby(\"col2\").size()\n",
    "\n",
    "# Print the result\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f9183-018c-4cbc-a5b6-ec45af4fbe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
